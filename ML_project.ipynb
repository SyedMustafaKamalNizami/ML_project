{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a6898e-4fd3-4356-b1cb-1bcaf7461052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Data Loading and Preprocessing ---\n",
      "\n",
      "--- 2. Training and Hyperparameter Tuning (GridSearchCV) ---\n",
      "\n",
      "STARTING: LOGISTIC REGRESSION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syedm\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION - Best F1 Score on Test: 0.6069\n",
      "Best parameters: {'classifier__C': 1}\n",
      "\n",
      "STARTING: RANDOM FOREST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syedm\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST - Best F1 Score on Test: 0.6204\n",
      "Best parameters: {'classifier__max_depth': 10, 'classifier__n_estimators': 100}\n",
      "\n",
      "STARTING: DEEP LEARNING MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syedm\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syedm\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEEP LEARNING MLP - Best F1 Score on Test: 0.6004\n",
      "Best parameters: {'classifier__lr': 0.001, 'classifier__max_epochs': 40, 'classifier__module__num_units': 50}\n",
      "\n",
      "======================================================================\n",
      "                FINAL COMPARATIVE MODEL PERFORMANCE\n",
      "======================================================================\n",
      "|                     |       F1 |   ROC AUC |\n",
      "|:--------------------|---------:|----------:|\n",
      "| random_forest       | 0.62037  |  0.832012 |\n",
      "| logistic_regression | 0.606925 |  0.835134 |\n",
      "| deep_learning_mlp   | 0.600414 |  0.830416 |\n",
      "\n",
      "======================================================================\n",
      "BEST PERFORMING MODEL: RANDOM FOREST (F1: 0.6204)\n",
      "======================================================================\n",
      "Accuracy: 0.7669\n",
      "F1 Score: 0.6204\n",
      "ROC AUC: 0.8320\n",
      "\n",
      "Classification Report (Best Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.79      0.83      1033\n",
      "         1.0       0.55      0.72      0.62       374\n",
      "\n",
      "    accuracy                           0.77      1407\n",
      "   macro avg       0.72      0.75      0.73      1407\n",
      "weighted avg       0.79      0.77      0.78      1407\n",
      "\n",
      "\n",
      "Pipeline saved as telco_churn_comparison_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, roc_auc_score\n",
    "import joblib\n",
    "\n",
    "# PyTorch and skorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# --- 1. Data Loading and Preprocessing (Unchanged) ---\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"\n",
    "    Loads the telco customer churn dataset and performs initial cleaning\n",
    "    \"\"\"\n",
    "    url = \"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\"\n",
    "    df = pd.read_csv(url)\n",
    "\n",
    "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "    df = df.drop('customerID', axis=1)\n",
    "    df = df.dropna()\n",
    "    df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_preprocessing_pipeline(X):\n",
    "    \"\"\"\n",
    "    Creates a preprocessing pipeline for numerical and categorical features\n",
    "    \"\"\"\n",
    "    categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    # \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "# --- 2. Deep Learning Model Definition (PyTorch - Unchanged) ---\n",
    "class ChurnMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multilayer Perceptron for Binary Classification (Customer Churn)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features=None, num_units=100, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        if num_features is None:\n",
    "            num_features = 30 \n",
    "\n",
    "        self.layer1 = nn.Linear(num_features, num_units)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.layer2 = nn.Linear(num_units, num_units // 2)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.layer3 = nn.Linear(num_units // 2, 1) # Output: 1 for binary classification (logit score)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.float() \n",
    "        \n",
    "        X = self.dropout1(torch.relu(self.layer1(X)))\n",
    "        X = self.dropout2(torch.relu(self.layer2(X)))\n",
    "        \n",
    "        # Returns raw logit scores (no sigmoid) for nn.BCEWithLogitsLoss\n",
    "        return self.layer3(X)\n",
    "\n",
    "\n",
    "# --- 3. Main Execution Function with Comparative Analysis (FIXED) ---\n",
    "def main_with_dl():\n",
    "    print(\"--- 1. Data Loading and Preprocessing ---\")\n",
    "    df = load_and_preprocess_data()\n",
    "    X = df.drop('Churn', axis=1)\n",
    "    y = df['Churn']\n",
    "\n",
    "    # CRUCIAL FIX: Convert y to float32 numpy array and reshape to (N, 1) for skorch/PyTorch\n",
    "    y = y.values.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "    # Split and Stratify\n",
    "    # y_test is a column vector here, but scikit-learn metrics handle the flattening later\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    "    )\n",
    "\n",
    "    preprocessor = create_preprocessing_pipeline(X)\n",
    "    \n",
    "    # Determine the input size for the MLP\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    num_features = X_train_processed.shape[1]\n",
    "    del X_train_processed \n",
    "\n",
    "    # Prepare Deep Learning Classifier using skorch wrapper\n",
    "    # Calculate class weights for imbalance handling in PyTorch\n",
    "    neg_count = np.sum(y_train == 0)\n",
    "    pos_count = np.sum(y_train == 1)\n",
    "    pos_weight = torch.tensor([neg_count / pos_count], dtype=torch.float32)\n",
    "\n",
    "    # \n",
    "    dl_model = NeuralNetClassifier(\n",
    "        ChurnMLP,\n",
    "        module__num_features=num_features,\n",
    "        criterion=nn.BCEWithLogitsLoss, \n",
    "        optimizer=optim.Adam,\n",
    "        max_epochs=20,\n",
    "        iterator_train__shuffle=True,\n",
    "        verbose=0,\n",
    "        criterion__pos_weight=pos_weight\n",
    "        # FIXED: Removed the invalid 'target_type' argument\n",
    "    )\n",
    "\n",
    "    # --- Define all models and their hyperparameter grids ---\n",
    "    models = {\n",
    "        'logistic_regression': {\n",
    "            'model': LogisticRegression(random_state=SEED, class_weight='balanced', max_iter=1000),\n",
    "            'params': {'classifier__C': [0.1, 1, 10]}\n",
    "        },\n",
    "        'random_forest': {\n",
    "            'model': RandomForestClassifier(random_state=SEED, class_weight='balanced'),\n",
    "            'params': {'classifier__n_estimators': [100, 200], 'classifier__max_depth': [10, 20]}\n",
    "        },\n",
    "        'deep_learning_mlp': {\n",
    "            'model': dl_model,\n",
    "            'params': {\n",
    "                'classifier__module__num_units': [50, 100],\n",
    "                'classifier__lr': [0.001, 0.01],\n",
    "                'classifier__max_epochs': [20, 40]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    best_model_name = \"\"\n",
    "    results = {}\n",
    "\n",
    "    print(\"\\n--- 2. Training and Hyperparameter Tuning (GridSearchCV) ---\")\n",
    "    \n",
    "    # --- Train and evaluate each model using gridsearchCV ---\n",
    "    for model_name, model_info in models.items():\n",
    "        print(f\"\\nSTARTING: {model_name.replace('_', ' ').upper()}\")\n",
    "\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model_info['model'])\n",
    "        ])\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            model_info['params'],\n",
    "            cv=3, \n",
    "            scoring='f1',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate on test set\n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        \n",
    "        # Predict probability for ROC AUC\n",
    "        if hasattr(grid_search.best_estimator_.named_steps['classifier'], 'predict_proba'):\n",
    "             y_pred_proba = grid_search.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "             # Skorch outputs a 2D array of probabilities when using BCEWithLogitsLoss\n",
    "             y_pred_proba = grid_search.predict_proba(X_test).ravel()\n",
    "        \n",
    "        # y_test must be flattened for scikit-learn metrics\n",
    "        y_test_flat = y_test.ravel()\n",
    "\n",
    "        f1 = f1_score(y_test_flat, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test_flat, y_pred_proba)\n",
    "        \n",
    "        results[model_name] = {'F1': f1, 'ROC AUC': roc_auc, 'Best Params': grid_search.best_params_}\n",
    "\n",
    "        print(f\"{model_name.replace('_', ' ').upper()} - Best F1 Score on Test: {f1:.4f}\")\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "        if f1 > best_score:\n",
    "            best_score = f1\n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_model_name = model_name\n",
    "\n",
    "    # --- 4. Final Comparative Analysis and Evaluation ---\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"                FINAL COMPARATIVE MODEL PERFORMANCE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Display results in a table\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    results_df = results_df.sort_values(by='F1', ascending=False)\n",
    "    \n",
    "    print(results_df[['F1', 'ROC AUC']].to_markdown())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"BEST PERFORMING MODEL: {best_model_name.replace('_', ' ').upper()} (F1: {best_score:.4f})\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Final evaluation of best model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    if hasattr(best_model.named_steps['classifier'], 'predict_proba'):\n",
    "         y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    else: \n",
    "         y_pred_proba = best_model.predict_proba(X_test).ravel()\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(y_test_flat, y_pred):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test_flat, y_pred):.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test_flat, y_pred_proba):.4f}\")\n",
    "    print(\"\\nClassification Report (Best Model):\")\n",
    "    print(classification_report(y_test_flat, y_pred))\n",
    "\n",
    "    # Save final pipeline to disk\n",
    "    joblib.dump(best_model, 'telco_churn_comparison_pipeline.joblib')\n",
    "    print(\"\\nPipeline saved as telco_churn_comparison_pipeline.joblib\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_with_dl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d6167-9565-41ad-bc64-ab1edb8d2ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
